{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling, BayesianParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "import os\n",
    "\n",
    "seed = 123\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
    "X = pd.read_table(path1, header=None, delim_whitespace=True)\n",
    "\n",
    "path2 = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
    "y = pd.read_table(path2, header=None, usecols=[0], squeeze=True, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,y1,y2 = train_test_split(X,y, random_state=seed, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>3212.46</td>\n",
       "      <td>2522.41</td>\n",
       "      <td>2200.2333</td>\n",
       "      <td>1173.8377</td>\n",
       "      <td>1.3281</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.6111</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>1.4650</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4936</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>2.6457</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>223.1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>3067.89</td>\n",
       "      <td>2570.93</td>\n",
       "      <td>2196.8000</td>\n",
       "      <td>1090.0084</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.3944</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>1.5001</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>127.2483</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.9411</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>127.2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2967.54</td>\n",
       "      <td>2573.09</td>\n",
       "      <td>2160.6000</td>\n",
       "      <td>1124.5821</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7122</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>1.4750</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4973</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>62.3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>3068.64</td>\n",
       "      <td>2498.02</td>\n",
       "      <td>2192.7556</td>\n",
       "      <td>867.3027</td>\n",
       "      <td>1.7393</td>\n",
       "      <td>100.0</td>\n",
       "      <td>123.4244</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>1.4404</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>414.4256</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>2.1984</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>414.4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>3080.89</td>\n",
       "      <td>2590.45</td>\n",
       "      <td>2162.7556</td>\n",
       "      <td>1006.7789</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.8744</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>45.7004</td>\n",
       "      <td>0.4989</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.3541</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>45.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>3182.35</td>\n",
       "      <td>2520.40</td>\n",
       "      <td>2187.7888</td>\n",
       "      <td>1350.3395</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9267</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1.4629</td>\n",
       "      <td>-0.0164</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.4462</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>139.6209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2997.94</td>\n",
       "      <td>2471.97</td>\n",
       "      <td>2214.1667</td>\n",
       "      <td>1705.2046</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.4633</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>1.4964</td>\n",
       "      <td>-0.0099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>136.9762</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1.7286</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>136.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>3006.80</td>\n",
       "      <td>2536.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4814</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.2344</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>545.6838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>3002.54</td>\n",
       "      <td>2549.85</td>\n",
       "      <td>2182.5555</td>\n",
       "      <td>1261.0898</td>\n",
       "      <td>1.2110</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.2922</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>1.2634</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>3.5944</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>248.6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>2978.15</td>\n",
       "      <td>2506.00</td>\n",
       "      <td>2153.9778</td>\n",
       "      <td>1192.6994</td>\n",
       "      <td>1.3522</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.9367</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>1.4035</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.4590</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>45.7019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows Ã— 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3       4      5         6       7    \\\n",
       "871   3212.46  2522.41  2200.2333  1173.8377  1.3281  100.0  101.6111  0.1211   \n",
       "385   3067.89  2570.93  2196.8000  1090.0084  1.3270  100.0   99.3944  0.1212   \n",
       "611   2967.54  2573.09  2160.6000  1124.5821  1.5257  100.0   98.7122  0.1246   \n",
       "1494  3068.64  2498.02  2192.7556   867.3027  1.7393  100.0  123.4244  0.1251   \n",
       "751   3080.89  2590.45  2162.7556  1006.7789  0.8736  100.0  106.8744  0.1220   \n",
       "...       ...      ...        ...        ...     ...    ...       ...     ...   \n",
       "1115  3182.35  2520.40  2187.7888  1350.3395  0.7945  100.0  101.9267  0.1200   \n",
       "863   2997.94  2471.97  2214.1667  1705.2046  0.9113  100.0  100.4633  0.1231   \n",
       "1459  3006.80  2536.87        NaN        NaN     NaN    NaN       NaN  0.0000   \n",
       "1493  3002.54  2549.85  2182.5555  1261.0898  1.2110  100.0  112.2922  0.1252   \n",
       "1042  2978.15  2506.00  2153.9778  1192.6994  1.3522  100.0  100.9367  0.1225   \n",
       "\n",
       "         8       9    ...     580       581     582     583     584     585  \\\n",
       "871   1.4650  0.0035  ...     NaN       NaN  0.4936  0.0131  0.0032  2.6457   \n",
       "385   1.5001 -0.0199  ...  0.0025  127.2483  0.4968  0.0096  0.0029  1.9411   \n",
       "611   1.4750  0.0248  ...     NaN       NaN  0.4973  0.0129  0.0030  2.6016   \n",
       "1494  1.4404 -0.0050  ...  0.0085  414.4256  0.5029  0.0111  0.0032  2.1984   \n",
       "751   1.4187  0.0012  ...  0.0017   45.7004  0.4989  0.0167  0.0040  3.3541   \n",
       "...      ...     ...  ...     ...       ...     ...     ...     ...     ...   \n",
       "1115  1.4629 -0.0164  ...     NaN       NaN  0.5023  0.0173  0.0040  3.4462   \n",
       "863   1.4964 -0.0099  ...  0.0057  136.9762  0.4991  0.0086  0.0026  1.7286   \n",
       "1459  1.4814  0.0180  ...     NaN       NaN  0.4974  0.0111  0.0034  2.2344   \n",
       "1493  1.2634  0.0052  ...     NaN       NaN  0.5045  0.0181  0.0048  3.5944   \n",
       "1042  1.4035  0.0222  ...     NaN       NaN  0.5012  0.0123  0.0035  2.4590   \n",
       "\n",
       "         586     587     588       589  \n",
       "871   0.0117  0.0262  0.0089  223.1018  \n",
       "385   0.0056  0.0071  0.0025  127.2483  \n",
       "611   0.0252  0.0157  0.0046   62.3881  \n",
       "1494  0.0068  0.0280  0.0085  414.4256  \n",
       "751   0.0119  0.0054  0.0017   45.7004  \n",
       "...      ...     ...     ...       ...  \n",
       "1115  0.0169  0.0236  0.0076  139.6209  \n",
       "863   0.0140  0.0192  0.0057  136.9762  \n",
       "1459 -0.0031  0.0168  0.0061  545.6838  \n",
       "1493  0.0049  0.0123  0.0037  248.6235  \n",
       "1042  0.0437  0.0200  0.0074   45.7019  \n",
       "\n",
       "[1175 rows x 590 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has  1175 observations and  590 features\n"
     ]
    }
   ],
   "source": [
    "print(\"The training set has \", x1.shape[0], \"observations and \", x1.shape[1], \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    590\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x1.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 590 are numerical features. Let's find how many columns have NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 418 features with at least 1 NaN\n"
     ]
    }
   ],
   "source": [
    "na_columns = []\n",
    "for col in x1.columns:\n",
    "    if x1.loc[:,col].isna().sum() > 0:\n",
    "        na_columns.append(col)\n",
    "        \n",
    "print(\"There are\", len(na_columns), \"features with at least 1 NaN\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there are columns that have <5 unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_columns = []\n",
    "for col in x1.columns:\n",
    "    if x1.loc[:,col].nunique() < 3:\n",
    "        unique_columns.append(col)\n",
    "\n",
    "len(unique_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if the target labels are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    0.933617\n",
       " 1    0.066383\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are not balanced, 93.3% of the observations are \"Pass\" and remaining are \"Fail\". Thus, the classifier must be abale to handle 'class_weight'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and modeling strategy:\n",
    "\n",
    "1. All features are numerical\n",
    "2. Majority of the features have null values => Imputation will be needed\n",
    "3. Features have different scales => scaling will be required\n",
    "4. 122 columns have less than 3 distinct values. This means either they have near constant variance or they might be categorical.  \n",
    "5. Imbalanced dataset\n",
    "\n",
    "\n",
    "Keeping this in mind, we will have to build a pipeline that will include:\n",
    "1. Standarddization\n",
    "2. Imputation\n",
    "3. Variance Threshold to remove near-constant values as they will have less predictive power\n",
    "4. Since number of features are very large, we will need to do dimentionality reduction\n",
    "5. Typically, use F1 or AUC as the metric since the labels are imbalanced. Also the classifier must be able to handle 'class_weight'.\n",
    "6. We will try three linear algorithms (Logistic, SVC, Ridge) and two tree-based (Random Forest & lightgbm), stacking ensemble and voting ensemble. All algorithms will be based on CV to measure its 'generalizability'.\n",
    "7. Finally, the final model for hyperparameter tuning will be based on:\n",
    "    - Simple\n",
    "    - Parsimonious\n",
    "    - Easy to maintain, debug and interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_weight = y1.value_counts(normalize=True)[1]\n",
    "pass_weight = 1-fail_weight\n",
    "\n",
    "weights = {-1:pass_weight, 1:fail_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=seed, class_weight = weights)\n",
    "rf = RandomForestClassifier(class_weight=weights, random_state=seed)\n",
    "svc = SVC(class_weight = weights, random_state=seed)\n",
    "lgbm = LGBMClassifier(objectibe='binary', random_state=seed)\n",
    "ridge = RidgeClassifier(class_weight = weights, random_state=seed)\n",
    "pca = PCA(n_components = 200)\n",
    "\n",
    "stack = [('svc',svc), ('lgbm',lgbm), ('lr',lr), ('rf',rf)]\n",
    "\n",
    "voting = VotingClassifier(stack, voting='soft')\n",
    "\n",
    "stacking = StackingClassifier(stack, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an empty dataframe to store results\n",
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify number components to keep in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca1=PCA()\n",
    "\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "])\n",
    "\n",
    "x_x = clf2.fit_transform(x1)\n",
    "\n",
    "\n",
    "\n",
    "pca1.fit(x_x)\n",
    "v=pca1.explained_variance_\n",
    "plt.plot(np.arange(1,len(v)+1), np.cumsum(v));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the plot above, the explained variance levels off after ~200 components. Thus, we can safely keep the first 200 components. This will reduce the number of features from 590 to 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"lr\"\n",
    "\n",
    "clf1 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classification', lr)\n",
    "])\n",
    "clf1.fit(x1, y1)\n",
    "\n",
    "score1 = cross_val_score(clf1, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name, 'auc':score1.mean(), 'auc_std':score1.std() }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"lr_PCA\"\n",
    "\n",
    "clf1 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', lr)\n",
    "])\n",
    "clf1.fit(x1, y1)\n",
    "\n",
    "score1 = cross_val_score(clf1, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name, 'auc':score1.mean(), 'auc_std':score1.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA, improved the AUC sightly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"svc_PCA\"\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', svc)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"ridge_PCA\"\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', ridge)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBM w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_PCA</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.053746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144\n",
       "4   lgbm_PCA  0.657564  0.053746"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"lgbm_PCA\"\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', lgbm)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_PCA</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.053746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_PCA</td>\n",
       "      <td>0.636927</td>\n",
       "      <td>0.060807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144\n",
       "4   lgbm_PCA  0.657564  0.053746\n",
       "5     rf_PCA  0.636927  0.060807"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"rf_PCA\"\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', lgbm)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier Ensemble w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_PCA</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.053746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_PCA</td>\n",
       "      <td>0.636927</td>\n",
       "      <td>0.060807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.662538</td>\n",
       "      <td>0.064144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144\n",
       "4   lgbm_PCA  0.657564  0.053746\n",
       "5     rf_PCA  0.636927  0.060807\n",
       "6     voting  0.662538  0.064144"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"voting\"\n",
    "\n",
    "lr = LogisticRegression(random_state=seed)\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "svc = SVC(random_state=seed, probability=True)\n",
    "lgbm = LGBMClassifier(objectibe='binary', random_state=seed)\n",
    "ridge1 = RidgeClassifier(random_state=seed)\n",
    "\n",
    "stack = [('svc',svc), ('lgbm',lgbm), ('lr',lr), ('rf',rf)]\n",
    "\n",
    "voting = VotingClassifier(stack, voting='soft')\n",
    "\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', voting)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Ensemble w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_PCA</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.053746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_PCA</td>\n",
       "      <td>0.636927</td>\n",
       "      <td>0.060807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.662538</td>\n",
       "      <td>0.064144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stacking</td>\n",
       "      <td>0.654393</td>\n",
       "      <td>0.060774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144\n",
       "4   lgbm_PCA  0.657564  0.053746\n",
       "5     rf_PCA  0.636927  0.060807\n",
       "6     voting  0.662538  0.064144\n",
       "7   stacking  0.654393  0.060774"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"stacking\"\n",
    "\n",
    "lr = LogisticRegression(random_state=seed)\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "svc = SVC(random_state=seed, probability=True)\n",
    "lgbm = LGBMClassifier(objectibe='binary', random_state=seed)\n",
    "ridge1 = RidgeClassifier(random_state=seed)\n",
    "\n",
    "stack = [('svc',svc), ('lgbm',lgbm), ('lr',lr), ('rf',rf)]\n",
    "\n",
    "stacking = StackingClassifier(stack, final_estimator=LogisticRegression())\n",
    "\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', pca),\n",
    "    ('classification', stacking)\n",
    "])\n",
    "clf2.fit(x1, y1)\n",
    "\n",
    "score2 = cross_val_score(clf2, X=x1, y=y1, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "result_df = result_df.append({'Classifier':name , 'auc':score2.mean(), 'auc_std':score2.std() }, ignore_index=True)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.072825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_PCA</td>\n",
       "      <td>0.666702</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_PCA</td>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.078973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_PCA</td>\n",
       "      <td>0.634436</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_PCA</td>\n",
       "      <td>0.657564</td>\n",
       "      <td>0.053746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_PCA</td>\n",
       "      <td>0.636927</td>\n",
       "      <td>0.060807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.662538</td>\n",
       "      <td>0.064144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stacking</td>\n",
       "      <td>0.654393</td>\n",
       "      <td>0.060774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier       auc   auc_std\n",
       "0         lr  0.665418  0.072825\n",
       "1     lr_PCA  0.666702  0.073192\n",
       "2    svc_PCA  0.675081  0.078973\n",
       "3  ridge_PCA  0.634436  0.063144\n",
       "4   lgbm_PCA  0.657564  0.053746\n",
       "5     rf_PCA  0.636927  0.060807\n",
       "6     voting  0.662538  0.064144\n",
       "7   stacking  0.654393  0.060774"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "1. SVC classfier has the best AUC of 67.5% followed by Logistic Regression at 66.6%\n",
    "2. The AUC scores are moderate and do not indicate that the features can't predict the pass/fail labels very accurately\n",
    "3. PCA reduced the number of features from 590 to 200. This will significantly reduce the train/inference times. Reducing the number of features did not affect the AUC much, in fact it improved it slightly.\n",
    "4. Using PCA makes the model less interpretable\n",
    "5. Using ensemble methods did not result in improving the best individual model \n",
    "6. All scores are based on mean cross-validated AUC. Std deviation of the AUC shows not significant deviation from mean. Hence we can expect the final model to generalize well witin AUC [0.6-0.74]\n",
    "7. Hyperdrive will be used to further tune the SVC + PCA model. All other transformations will be kept the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "'''\n",
    "\n",
    "Training script for Udacity Project 3\n",
    "Sandeep Pawar\n",
    "Ver 1\n",
    "Date Jan 25, 2021\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from azureml.core.run import Run\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "seed = 123\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "def load_data(dataframe):\n",
    "    \n",
    "    # Load data with all the columns from the source\n",
    "    # x is teh training data\n",
    "    # y is the label for the training data\n",
    "    \n",
    "    x = dataframe.drop('y', axis=1)\n",
    "    \n",
    "    y = dataframe['y'] \n",
    "    \n",
    "    return x, y \n",
    "\n",
    "x, y = load_data(dataframe)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    weights = {-1:0.9334, 1:(1-0.9334)}\n",
    "\n",
    "    parser.add_argument('--impute', type=str, default='median', help=\"Imputation Strategy\")\n",
    "    parser.add_argument('--kernel', type=str, default=\"rbf\", help=\"Kernel for SVC\")\n",
    "    parser.add_argument('--gamma', type=str, default='auto', help=\"Gamma value\")\n",
    "    parser.add_argument('--penalty', type=float, default=1, help=\"Penalty\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run.log(\"Imputation:\", str(args.impute))\n",
    "    run.log(\"kernel:\", str(args.kernel))\n",
    "    run.log(\"Gamma:\", str(args.gamma))\n",
    "    run.log(\"penalty:\", str(args.penalty))\n",
    "    \n",
    "    clf = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=args.impute)), # To impute missing values\n",
    "    ('threshold', VarianceThreshold(0.01)), # Remove near-constant features\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', PCA(n_components = 200)),\n",
    "    ('classification', (SVC(class_weight = weights, \n",
    "                           random_state=seed, \n",
    "                           kernel = args.kernel, \n",
    "                           C = args.penalty,\n",
    "                           gamma = args.gamma, \n",
    "                           probability =True)))\n",
    "    ])\n",
    "        \n",
    "    clf.fit(x, y)    \n",
    "    \n",
    "    score = cross_val_score(clf, X=x, y=y, cv=5, scoring = 'roc_auc')\n",
    "        \n",
    "    \n",
    "    run.log(\"Mean_AUC\", np.float( score.mean()))\n",
    "\n",
    "    #Serialize the model\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    joblib.dump(clf, 'outputs/hyperDrive_{}_{}'.format(args.kernel,args.gamma, args.penalty))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure ML Hyperdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Azure Workspace & Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws =Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"Project3\")\n",
    "\n",
    "print(ws.get_details()['id'])\n",
    "\n",
    "compute_name = \"DS2V2\"\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    vm = ComputeTarget(ws, compute_name)\n",
    "    print(f\"{compute_name} exists already\")\n",
    "except:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_D2_V2\", max_nodes=4)\n",
    "    vm = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "    \n",
    "vm.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperdrive Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameter sampler\n",
    "\n",
    "\n",
    "\n",
    "param_space = { \n",
    "                                    \"--impute\"     : choice('mean', 'median'), \n",
    "                                    \"--kernel\": choice(\"rbf\",\"linear\"),\n",
    "                                    \"--gamma\": choice(\"auto\",\"scale\"),\n",
    "                                    \"--penalty\": choice(0.01,1,10,20,100)  \n",
    "                                    \n",
    "              }\n",
    "\n",
    "sampling = RandomParameterSampling(param_space)\n",
    "\n",
    "# Specifying Bandit Policy. \n",
    "# ROC will be evaluated at every run, starting from 21st run. \n",
    "# If the performance in the successive runs is below 91% of the best performing run, HPO will be stopped\n",
    "\n",
    "\n",
    "policy = BanditPolicy(evaluation_interval=1, slack_factor=0.1, delay_evaluation=20)\n",
    "\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "import shutil\n",
    "shutil.copy('train.py', './training')\n",
    "    \n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(source_directory='./training', \n",
    "              compute_target=vm, \n",
    "              entry_script='train.py')\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(estimator=est, \n",
    "                                     policy=policy, \n",
    "                                     primary_metric_name=\"AUC\",\n",
    "                                     hyperparameter_sampling=sampling,\n",
    "                                     max_total_runs=200,\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
